
---
title: "STAT202 Assignment 3: Multiple Linear Regression II"
author: "Your Name"
date: "Due on 14th August 2024"
output:
   word_document:
      reference_docx: "template.docx"
---

#Introduction

This document contains the analysis for Assignment 3. It explores the aquatic_toxicity dataset using multiple linear regression to understand the relationships between various predictors and the response variable LC50. The analysis will follow these steps:

\newpage

Step 0: setup
loading libraries:





---
title: "STAT202 Lab 3: Multiple Linear Regression START"
author: "David Ewing"
date: "Due on 7 August 2024"
output: 
  word_document:
    reference_docx: "template.docx"
---

# Introduction
This document contains the analysis for Lab 2. It explores biometric data using multiple linear regression to understand the relationships between various predictors and the response variable weight_kg. The analysis will follow these steps:"
  
\newpage 

# Step 0: setup
loading  libraries:

```{r setup, include=TRUE}

set.seed(82171165)   #set seed 

knitr::opts_chunk$set(
  echo    = TRUE, # Show all code by default
  message = TRUE, # Include package messages
  warning = TRUE  # Include warnings if they occur
)



library(conflicted)
library(tidyverse)
library(readxl)
library(readr) 
library(performance)
library(GGally)
library(flextable)
library(broom)
library(skimr)
library(data.table)
library(lmtest)  
library(leaps)
conflict_prefer("filter", "dplyr"); conflict_prefer("select", "dplyr")

```

\newpage 

# Step 1: Read aquatic_toxicity.xlsx

```{r step1, echo=TRUE, message=TRUE}
# Load the data
toxic <- read_excel("../data/aquatic_toxicity.xlsx")



``` 



# Step 2: Select a random sample of 500 rows 

```{r step2, echo=TRUE, message=TRUE}
set.seed(82171165)

toxic_rows   <- nrow(toxic)
toxic_sample <- toxic |> slice_sample(n = 500) # without replacement
my_toxic     <- toxic_sample

# Summarise missing values 
# View the first few rows of the sample

skim_toxic <- skim(my_toxic) |>
  select(skim_variable, n_missing)
skim_toxic                           
head(toxic_sample)                   

 
```

\newpage

# Step 3: Estimate the correlations between all variables

```{r step3, echo=TRUE, message=TRUE}


cors <- cor(my_toxic) # Estimate 

cors
```
# Step 4: Top variables to predict LC50 

```{r step4, echo=TRUE, message=FALSE, fig.width=8, fig.height=6}

# 3 variables with the highest correlation with LC50
lc50_sort <- sort(cors["lc50", ], decreasing = TRUE)
lc50_sort <- lc50_sort[lc50_sort != 1]
top_3     <- names(lc50_sort[1:3])

lc50_matrix <- my_toxic[, c(top_3, "lc50")] |>
  ggpairs(
    lower = list(continuous = wrap("smooth", method = "lm", se = TRUE)),
    title = "Scatterplot Matrix: 3 top variables to predict LC50\nwith Confidence Interval"
  ) +
  theme_bw()

```
\newpage 

```{r }

lc50_matrix

```

---

A positive correlation between **mlogp** and **LC50**; with weaker positive relationships for **rdchi** and **LC50**; and an insiginficatn association between  **tpsa** and **LC50**. Each relationship appear generally linear but variability, particularly in **rdchi**, could affect predictability. THere has been no attempt to remove outliers. 

---

\newpage 

# Step 5: multiple linear regression model to predict LC50

```{r step5, echo=TRUE, message=TRUE}

lc50_arg <- as.formula(paste("lc50 ~ ", paste(top_3, collapse = " + ")))
m1       <- lm(lc50_arg, data = my_toxic)
summary(m1)
tidy(m1)
```

---

$$
LC50 = 2.6804 + 0.7416 \cdot \text{mlogp} - 0.2175 \cdot \text{rdchi} + 0.0159 \cdot \text{tpsa}
$$

---

\newpage 

# Step 6: Fit All Regression Subsets using adjusted R-squared

```{r Step 6 }

all_models <- regsubsets(lc50 ~ ., data = my_toxic)
plot(all_models, scale = "adjr2", 
     main = expression("Regression Subsets (Adjusted " ~ R^2 ~ ")"))
```

---

Both mlogp and tpsa appear here and in the coorelation matrix as good and perhaps reliable predictors for LC50, however, saacc and nn are selected the regression subsets relative to adjusted r-squared. This suggest that while they may not be strong standalone predictors, they may reduce the variablility when added to  combinations with other variables like mlogp.  

---

\newpage

# Step 7: Fit the Best Model and Compare 

```{r Step7 }

# Fit the best model identified in Step 6
m2_arg1 <- lc50 ~ saacc + nn + mlogp  # Based on the best subset from Step 6
m2        <- lm(m2_arg1, data = my_toxic)

# Summary of the best model
summary(m2)

# Compare Adjusted R² and Residual Standard Error with Step 5 model
m1_adjr2 <- summary(m1)$adj.r.squared
m1_rse    <- summary(m1)$sigma

m2_adjr2 <- summary(m2)$adj.r.squared
m1_rse    <- summary(m2)$sigma

# Create a dataframe for comparison
comparison_df <- data.frame(
  Metric = c("Adjusted R²", "Residual SE"),
  `m1` = c(round(m1_adjr2, 4), round(m2_adjr2, 4)),
  `m2` = c(round(m2_adjr2, 4), round(m1_rse, 4))
)



comparison_table <- flextable(comparison_df) %>%
  set_caption("Comparison of Regression Models: Step 5 vs Step 7") %>%
  bg(part = "header", bg = "#D3D3D3") %>%  # Grey header
  theme_box() %>%  #  border styling
  align(j = 1,   align = "left", part = "all") %>%  # Left-align Metric column
  align(j = 2:3, align = "center", part = "all") %>%  # Centre-align model columns
  border_inner_v(part = "all") %>%  #  vertical 
  border_inner_h(part = "all") %>%  #  horizontal 
  border_outer(part = "all") %>%    #  outer 
  autofit()  

# Display the table
comparison_table

```

---

While m2 includes saacc and nn, which may reduce multicollinearity, it does not outperform m1 in terms of predictive power or error minimisation. m1 has a higher adjusted r-square indicating that it explains more vaariance of LC50 than m2. The residule SE for m1 is significantly lower than m2 meaning that m1 provides a more precise model of LC50 than m2. 

---

\newpage


# Step8: Diagnostic Plots for Model Residuals and to Check Assumptions

```{r Step8, fig.width = 7, fig.height = 5}

check_model(m2)

m2_residuals <- residuals(m2) 
```


\newpage
\newpage


```{r }

metrics_df <- data.frame(
  Metric = c(
    "Linearity",
    "Homoscedasticity",
    "Normality of Residuals",
    "Influential Observations",
    "Collinearity",
    "Posterior Predictive Check"
  ),
  Assumption_Met = c(
    "No, deviations from linearity in the Residuals vs Fitted plot.",
    "No, increasing variance of residuals indicates heteroscedasticity.",
    "No, Q-Q plot shows deviations from normality at the tails.",
    "No, some influential points (e.g., 388, 258) are identified.",
    "Yes, VIF values are below 5, indicating low multicollinearity..",
    "Yes, reasonable alignment."
  )
)


metrics_table <- flextable(metrics_df) %>%
  set_caption("Diagnostic Metrics and Assumption Validation") %>%
  bg(part = "header", bg = "#D3D3D3") %>%  # Grey header
  theme_box() %>%
  align(j = 1, align = "left", part = "all") %>%  # Left-align Metric column
  align(j = 2, align = "left", part = "all") %>%  # Left-align Assumption_Met column
  border_inner_v(part = "all") %>%  # Add vertical borders
  border_inner_h(part = "all") %>%  # Add horizontal borders
  border_outer(part = "all") %>%    # Add outer borders
  autofit()  # Automatically fit content
```

\newpage 

```{r }
# Display the table
metrics_table


```

---

The posterior predictive check shows reasonable alignment between the model-predicted LC50 and observed data. The Residuals vs Fitted Values plot indicates curvature, suggesting potential non-linearity in the predictor-response relationships. The Scale-Location plot shows increasing residual variance as fitted values increase, discrediting the assumption of homoscedasticity. Influential observations, such as points 388 and 258, are flagged as close to the Cook’s distance lines and may disproportionately influence the model. The Variance Inflation Factor (VIF) values for the predictors (mlogp, nn, saacc) are all below 5, indicating low multicollinearity and stability. The Q-Q plot shows deviations from the normal at the tails, suggesting that residuals are not perfectly normally distributed.

---